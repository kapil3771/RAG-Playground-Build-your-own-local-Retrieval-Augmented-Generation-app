RAG Pipeline with Ollama + Local Embeddings + FAISS

Retrieve & Augment Pipeline (RAG) with:
	â€¢	Local LLM: Ollama (gemma:2b)
	â€¢	Local Embedding Model: sentence-transformers/all-MiniLM-L6-v2
	â€¢	Vector Store: FAISS (with persistence)
	â€¢	Context: YouTube Transcript or Manual Transcript
	â€¢	Framework: LangChain + Ollama + FAISS + Sentence Transformers

â¸»

Project Structure

rag-playground/
â”œâ”€â”€ rag.py              # Main RAG pipeline
â”œâ”€â”€ embeddings/
â”‚   â””â”€â”€ local_embedding_model.py
â”œâ”€â”€ transcript.txt      # Your transcript to process
â”œâ”€â”€ faiss_index_folder/ # FAISS index (auto created)
â”œâ”€â”€ run.sh              # Run script
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE


â¸»

Setup Instructions

1. Clone the repo & enter folder

git clone https://github.com/yourusername/rag-playground.git
cd rag-playground
```

2ï¸âƒ£ **Create virtual environment**:

```bash
python3.10 -m venv genai-env
source genai-env/bin/activate
```

3ï¸âƒ£ **Install dependencies**:

```bash
pip install -r requirements.txt
```

4ï¸âƒ£ **Run Ollama server**:

```bash
ollama serve
```

ğŸ‘‰ In **another terminal** (same env or not):

```bash
ollama pull gemma:2b

5. Provide transcript

Place your transcript in:

transcript.txt

(Plain text file)

6. Run the pipeline

./run.sh

Or to force clean the FAISS index:

./run.sh --clean


â¸»

Example Questions

questions = [
    "What is nuclear fusion?",
    "What temperature is needed for fusion?",
    "What are the challenges in achieving fusion?",
    "What does the sun use for its energy?",
    "Is plasma mentioned in the context?"
]


â¸»

Features
	â€¢	Works fully offline
	â€¢	No OpenAI API keys required
	â€¢	Ollama serves LLM locally
	â€¢	SentenceTransformers for embeddings
	â€¢	FAISS persistence â€“ avoids recomputing embeddings
	â€¢	Modular and clean code

â¸»

Notes
	â€¢	You can replace gemma:2b with any other Ollama model (e.g. mistral, llama3, qwen, etc).
	â€¢	You can use any sentence-transformers embedding model.
	â€¢	The pipeline is modular and extensible.

â¸»

License

MIT License
See LICENSE file.

â¸»

Contribution

Pull requests welcome! If you like this project, please â­ the repo.

â¸»

Enjoy building your RAG applications!